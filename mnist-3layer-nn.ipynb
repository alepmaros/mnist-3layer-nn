{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabalho Prático 1 - Aprendizado de Máquina\n",
    "<font size=4>Nome: Alexandre Maros<br></font>\n",
    "<font size=3>UFMG - 2018/1</font>\n",
    "\n",
    "\n",
    "Blabla..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "import os\n",
    "\n",
    "pd.options.display.max_rows = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Leitura dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encontrar Diretorio Atual\n",
    "diretorio_atual = os.path.realpath('.')\n",
    "\n",
    "# Ler o arquivo de entrada\n",
    "dados = pd.read_csv(os.path.join(diretorio_atual, \"data_tp1\"), sep=\",\", header=None)\n",
    "\n",
    "# Armazenar o label correto dos numeros\n",
    "dados = dados.rename(columns = {0:'label'})\n",
    "y = dados.label\n",
    "\n",
    "# Retirar a primeira coluna referente aos labels\n",
    "X = dados.drop(\"label\", axis=1)\n",
    "\n",
    "# Modificar o nome das colunas\n",
    "num_imagens = X.shape[1]\n",
    "X.columns = [ int(x) for x in range(0, num_imagens)] \n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Visualização dos dados\n",
    "\n",
    "Nesta etapa..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualização dos três primeiro dígitos do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digitos = [ X.loc[0,:], X.loc[1,:], X.loc[2,:] ]\n",
    "labels = [ y[0], y[1], y[2] ]\n",
    "\n",
    "# 784 colunas correspondem a uma imagem de 28x28\n",
    "plot1 = np.reshape(digitos[0].values, (28, 28))\n",
    "plot2 = np.reshape(digitos[1].values, (28, 28))\n",
    "plot3 = np.reshape(digitos[2].values, (28, 28))\n",
    "\n",
    "fig=plt.figure(figsize=(8, 8))\n",
    "\n",
    "# Plot the digits\n",
    "fig.add_subplot(4, 4, 1)\n",
    "plt.imshow(plot1, cmap='gray_r')\n",
    "plt.title('Label: {}'.format(labels[0]))\n",
    "\n",
    "fig.add_subplot(4, 4, 2)\n",
    "plt.imshow(plot2, cmap='gray_r')\n",
    "plt.title('Label: {}'.format(labels[1]))\n",
    "\n",
    "fig.add_subplot(4, 4, 3)\n",
    "plt.imshow(plot3, cmap='gray_r')\n",
    "plt.title('Label: {}'.format(labels[2]))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificando a distribuição dos dígitos\n",
    "\n",
    "É interessante verificar a disposição (frequência) dos dígitos no dataset. Se tiver muitos digitos 1 e poucos dígitos 9 isso pode levar a uma má previsão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y.value_counts(normalize=True).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os dígitos parecem estar bem distribuídos, sendo que os dígitos 0 e 5 são os dois digitos que menos aparecem (9.2% dos dígitos são o dígito 0 e 0.912% dos digitos são o dígito 5). O dígito 1 é o que mais aparece, com sua frequência em 11%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Construção dos Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "X = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(estimator, X, y,\n",
    "        cv=cv, n_jobs=n_jobs, train_sizes=train_sizes, scoring='neg_log_loss')\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPClassifier(solver='sgd', activation='logistic', batch_size='auto', early_stopping=False,\n",
    "                    hidden_layer_sizes=(50,), learning_rate_init=0.01, max_iter=200, momentum=0.5,\n",
    "                    shuffle=True, verbose=False)\n",
    "\n",
    "plot_learning_curve(clf, \"Titulo\", X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_scores_varying_lr(title, X, y, hidden_layer_sizes, batch_size, ylim=None, cv=10,\n",
    "                        scoring='neg_log_loss', n_jobs=1, train_sizes=np.linspace(.1, 1.0, 10)):\n",
    "\n",
    "    types = ['o-', '+-', 'D-']\n",
    "    t = 0\n",
    "    \n",
    "    scores = []\n",
    "    for i in [0.01, 0.1, 0.5]:\n",
    "        \n",
    "        estimator = MLPClassifier(solver='sgd', activation='logistic', batch_size=batch_size, early_stopping=False,\n",
    "                    hidden_layer_sizes=hidden_layer_sizes, learning_rate_init=i, max_iter=200, momentum=0.9,\n",
    "                    shuffle=True, verbose=False)\n",
    "        \n",
    "        train_sizes, train_scores, test_scores = learning_curve(estimator, X, y, \n",
    "            cv=cv, n_jobs=n_jobs, train_sizes=train_sizes, scoring=scoring)\n",
    "        \n",
    "        train_scores_mean = np.mean(train_scores, axis=1)\n",
    "        train_scores_std = np.std(train_scores, axis=1)\n",
    "        test_scores_mean = np.mean(test_scores, axis=1)\n",
    "        test_scores_std = np.std(test_scores, axis=1)\n",
    "        \n",
    "        scores.append({'learning_rate': i,\n",
    "                       'batch_size': batch_size,\n",
    "                       'hidden_layer_sizes': hidden_layer_sizes,\n",
    "                       'legend_type': types[t],\n",
    "                       'train_sizes': train_sizes,\n",
    "                       'train_scores': train_scores,\n",
    "                       'test_scores': test_scores,\n",
    "                       'train_scores_mean': train_scores_mean,\n",
    "                       'train_scores_std': train_scores_std,\n",
    "                       'test_scores_mean': test_scores_mean,\n",
    "                       'test_scores_std': test_scores_std})\n",
    "\n",
    "        t = t + 1\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variaveis\n",
    "# batch_size, hidden_layer_sizes, learning_rate_init, max_iter (num epochs)\n",
    "\n",
    "#print(\"1.\")\n",
    "#mlp_25_minibatch50 = calculate_scores_varying_lr(\"Teste\", X, y, 25, 50)\n",
    "#print(\"2.\")\n",
    "#mlp_50_minibatch50 = calculate_scores_varying_lr(\"Teste\", X, y, 50, 50)\n",
    "#print(\"3.\")\n",
    "#mlp_100_minibatch50 = calculate_scores_varying_lr(\"Teste\", X, y, 100, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scores(ax, plot):\n",
    "    l = []\n",
    "    for i in (0, 1, 2):\n",
    "        ax.fill_between(plot[i]['train_sizes'], plot[i]['train_scores_mean'] - plot[i]['train_scores_std'],\n",
    "                            plot[i]['train_scores_mean'] + plot[i]['train_scores_std'], alpha=0.1,\n",
    "                             color=\"r\")\n",
    "        ax.fill_between(plot[i]['train_sizes'], plot[i]['test_scores_mean'] - plot[i]['test_scores_std'],\n",
    "                         plot[i]['test_scores_mean'] + plot[i]['test_scores_std'], alpha=0.1, color=\"g\")\n",
    "        leg1, = ax.plot(plot[i]['train_sizes'], plot[i]['train_scores_mean'], plot[i]['legend_type'], color=\"r\",\n",
    "                 label=\"Training score \" + str(i))\n",
    "        leg2, = ax.plot(plot[i]['train_sizes'], plot[i]['test_scores_mean'], plot[i]['legend_type'], color=\"g\",\n",
    "                     label=\"Cross-validation score\" + str(i))\n",
    "        \n",
    "        l.append(leg1)\n",
    "        l.append(leg2)\n",
    "        \n",
    "        ax.set_xlabel('Batch Size: ' + str(plot[i]['batch_size']), fontsize=18)\n",
    "        ax.set_ylabel('Neuronios: ' + str(plot[i]['hidden_layer_sizes']), fontsize=18)\n",
    "        \n",
    "        ax.ylim=(-3, 0)\n",
    "        \n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "\n",
    "fig=plt.figure(figsize=(18, 16), dpi= 80, facecolor='w', edgecolor='k')\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import Grid\n",
    "grid = Grid(fig, rect=111, nrows_ncols=(3,3),\n",
    "            axes_pad=0.25, label_mode='L',\n",
    "            )\n",
    "\n",
    "i = 0\n",
    "#plots = [mlp_25_minibatch50, mlp_50_minibatch50, mlp_100_minibatch50, \n",
    "#         mlp_25_minibatch50, mlp_50_minibatch50, mlp_100_minibatch50, \n",
    "#         mlp_25_minibatch50, mlp_50_minibatch50, mlp_100_minibatch50]\n",
    "l = []\n",
    "for ax in grid:\n",
    "    l = plot_scores(ax, mlp_25_minibatch50[i])\n",
    "    ax.title.set_visible(False)\n",
    "    i = i + 1\n",
    "\n",
    "fig.legend(l, l, 'upper right')\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf.predict_proba(X.loc[1,:].values.reshape(1, -1))\n",
    "\n",
    "#clf.fit(X_train, y_train)\n",
    "#predictions = clf.predict_proba(X_test)\n",
    "#log_loss(y_test, predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
